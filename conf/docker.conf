# Filter unnecessary fields from the input, and map extra fields
<filter docker.source>
   @type       record_transformer
   enable_ruby true
   remove_keys ["CONTAINER_TAG","SYSLOG_IDENTIFIER","_SYSTEMD_UNIT","_HOSTNAME","CONTAINER_NAME","_GID","_CAP_EFFECTIVE","SYSLOG_FACILITY","PRIORITY","_BOOT_ID","_CMDLINE","_COMM","_EXE","_SYSTEMD_CGROUP","_SYSTEMD_SLICE","_TRANSPORT","_UID","__CURSOR","__MONOTONIC_TIMESTAMP","_SELINUX_CONTEXT","__REALTIME_TIMESTAMP","_PID","CONTAINER_ID","CONTAINER_ID_FULL","_MACHINE_ID","_SOURCE_REALTIME_TIMESTAMP","_SYSTEMD_INVOCATION_ID"]
   <record>
      environment       "#{ENV['ENVIRONMENT_NAME']}"
      SERVICE_NAME      ${ record["CONTAINER_NAME"] != nil && record["CONTAINER_NAME"].split("_").length >= 2 ? record["CONTAINER_NAME"].split("_")[1].split(".")[0] : "" }
   </record>
</filter>

# Attempt to parse the MESSAGE field as JSON
<filter docker.source >
   @type parser
   format multi_format
   key_name MESSAGE

   reserve_data true
   suppress_parse_error_log false

   <pattern>
      # Parse the MESSAGE field as json, and merge the new fields into the log message
      format json
   </pattern>
   <pattern>
      # Not JSON, passthrough
      format none
      message_key MESSAGE
   </pattern>
</filter>

# Kinesis analytics streams don't appear to support json fields with '@' - we will continue to send @time however
<filter docker.source>
   @type       record_transformer
   enable_ruby true
   <record>
      event_time ${ record["@time"] != nil ? record["@time"] : "" }
   </record>
</filter>

#<match docker.source>
#   @type rewrite_tag_filter
#
#   # Process any monitoring_event
#   <rule>
#      key monitoring_event
#      pattern true
#      tag docker.monitoring_event
#   </rule>
#</match>
